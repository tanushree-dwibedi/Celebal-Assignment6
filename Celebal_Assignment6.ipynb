{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/g4dlzJZ5Ufj8b/W4N19L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanushree-dwibedi/Celebal-Assignment6/blob/main/Celebal_Assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TamAQYQkHJDf",
        "outputId": "a71f1f26-0f70-49c2-fdbb-0ee382f9dd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Model Performance:\n",
            "                     Accuracy  Precision    Recall  F1 Score\n",
            "Logistic Regression  0.973684   0.972222  0.985915  0.979021\n",
            "Decision Tree        0.947368   0.957746  0.957746  0.957746\n",
            "Random Forest        0.964912   0.958904  0.985915  0.972222\n",
            "SVM                  0.982456   0.972603  1.000000  0.986111\n",
            "\n",
            "Tuned SVM Best Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Tuned RF Best Params: {'n_estimators': 50, 'min_samples_split': 5, 'max_depth': 20}\n",
            "\n",
            "Tuned SVM Performance:\n",
            "Accuracy: 0.9824561403508771\n",
            "Precision: 0.9726027397260274\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9861111111111112\n",
            "\n",
            "Tuned RF Performance:\n",
            "Accuracy: 0.956140350877193\n",
            "Precision: 0.9583333333333334\n",
            "Recall: 0.971830985915493\n",
            "F1 Score: 0.965034965034965\n"
          ]
        }
      ],
      "source": [
        "# Prerequisites\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "print(\"\\nInitial Model Performance:\")\n",
        "print(pd.DataFrame(results).T)\n",
        "\n",
        "# GridSearchCV for SVM\n",
        "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
        "grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='f1')\n",
        "grid_search_svm.fit(X_train, y_train)\n",
        "\n",
        "# RandomizedSearchCV for Random Forest\n",
        "param_dist_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "random_search_rf = RandomizedSearchCV(RandomForestClassifier(), param_dist_rf, n_iter=10, cv=5, scoring='f1', random_state=42)\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate tuned models\n",
        "print(\"\\nTuned SVM Best Params:\", grid_search_svm.best_params_)\n",
        "print(\"Tuned RF Best Params:\", random_search_rf.best_params_)\n",
        "\n",
        "for name, model in [(\"Tuned SVM\", grid_search_svm.best_estimator_), (\"Tuned RF\", random_search_rf.best_estimator_)]:\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3o1b1MCVHKxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}